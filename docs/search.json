[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Remotely sensing - Learnig diary",
    "section": "",
    "text": "About\n\n\n\n\n\nHi! I’m Siyu Yang. I earned my undergraduate degree in management from the University of Electronic Science and Technology of China. During my undergraduate studies, I learned a wide range of subjects—not only management knowledge but also plenty of city-related topics such as urban planning, design, and even some coding techniques. I have a keen interest in cities and believe that the future of urban development is inseparable from the advancement of science and technology. This led me to choose CASA for further specialization, aiming to deepen my understanding of how technology can be applied to urban challenges.\nWhile I have not yet had the opportunity to gain formal professional experience, my academic journey has been rich with involvement in various research projects and volunteer initiatives. One notable project was my engagement in urban planning research for Chengdu Wenjiang District, where I conducted thorough field research and analyzed its developmental challenges. This effort, particularly praised by my professors, underscores my proactive involvement in urban planning. Additionally, my work with a volunteer team, where I participated in teaching and organizing fundraising events in disadvantaged areas, not only taught me the true essence of dedication but also deepened my understanding of the critical role of urban development in enhancing social welfare and education.\nRealizing that data is indispensable to our lives and the development of cities, I began to understand the urgent need for data processing skills. This website is my remotely sensing learning diary. Through this module, I expect to learn how to apply technology, especially remotely sensing technology, to address global challenges such as climate change, urban planning and environmental protection, thereby improving the ability of urban sustainable development."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "9  References",
    "section": "",
    "text": "Navalgund, Ranganath R., et al. \"Remote Sensing Applications: An Overview.\" Current Science, vol. 93, no. 12, 2007, pp. 1747–1766, www.jstor.org/stable/24102069?saml_data=eyJzYW1sVG9rZW4iOiJlODcwNjFkNC01YzA1LTQ1YWItYjIzZS0xZWI2NDgxZGU0OTUiLCJpbnN0aXR1dGlvbklkcyI6WyIxOGVlZTJmYS1mODcxLTQwYTktODI4NS1mNTRlYzdhMDM4MjciXX0&seq=1. Accessed 22 Mar. 2024.\n\"Search.\" Www.esa.int, www.esa.int/esearch?q=india. Accessed 22 Mar. 2024.\nIrons, James R, and Gary W Petersen. \"Texture Transforms of Remote Sensing Data.\" Remote Sensing of Environment, vol. 11, Jan. 1981, pp. 359–370, https://doi.org/10.1016/0034-4257(81)90033-x.\nPei, Fengsong, et al. \"Application of Normalized Difference Vegetation Index (NDVI) for the Detection of Extreme Precipitation Change.\" Forests, vol. 12, no. 5, 9 May 2021, p. 594, https://doi.org/10.3390/f12050594.\nAHMEDABAD HEAT ACTION PLAN 2016 GUIDE to EXTREME HEAT PLANNING in AHMEDABAD, INDIA EASY READ VERSION.\nAzhar, Gulrez, et al. \"Heat Wave Vulnerability Mapping for India.\" International Journal of Environmental Research and Public Health, vol. 14, no. 4, 30 Mar. 2017, p. 357, www.ncbi.nlm.nih.gov/pmc/articles/PMC5409558/, https://doi.org/10.3390/ijerph14040357.\nKnowlton, Kim, et al. \"Development and Implementation of South Asia's First Heat-Health Action Plan in Ahmedabad (Gujarat, India).\" International Journal of Environmental Research and Public Health, vol. 11, no. 4, 25 Mar. 2014, pp. 3473–3492, https://doi.org/10.3390/ijerph110403473.\nTamiminia, Haifa, et al. \"Google Earth Engine for Geo-Big Data Applications: A Meta-Analysis and Systematic Review.\" ISPRS Journal of Photogrammetry and Remote Sensing, vol. 164, June 2020, pp. 152–170, https://doi.org/10.1016/j.isprsjprs.2020.04.001.\nPal, M. \"Random Forest Classifier for Remote Sensing Classification.\" International Journal of Remote Sensing, vol. 26, no. 1, Jan. 2005, pp. 217–222, https://doi.org/10.1080/01431160412331269698.\nTian, Shaohong, et al. \"Random Forest Classification of Wetland Landcovers from Multi-Sensor Data in the Arid Region of Xinjiang, China.\" Remote Sensing, vol. 8, no. 11, 1 Nov. 2016, p. 954, www.mdpi.com/2072-4292/8/11/954/htm, https://doi.org/10.3390/rs8110954. Accessed 20 May 2020.\nLiu, Kai, et al. \"An Assessment of Urban Surface Energy Fluxes Using a Sub-Pixel Remote Sensing Analysis: A Case Study in Suzhou, China.\" ISPRS International Journal of Geo-Information, vol. 5, no. 2, 1 Feb. 2016, p. 11, www.mdpi.com/2220-9964/5/2/11, https://doi.org/10.3390/ijgi5020011. Accessed 22 Mar. 2024.\nRahman, Atiqur, et al. \"Assessment of Land Use/Land Cover Change in the North-West District of Delhi Using Remote Sensing and GIS Techniques.\" Journal of the Indian Society of Remote Sensing, vol. 40, no. 4, 5 Jan. 2012, pp. 689–697, https://doi.org/10.1007/s12524-011-0165-4.\n\"Europe Braces for Sweltering July.\" Www.esa.int, www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-3/Europe_braces_for_sweltering_July.\nStreutker, D. R. \"A Remote Sensing Study of the Urban Heat Island of Houston, Texas.\" International Journal of Remote Sensing, vol. 23, no. 13, Jan. 2002, pp. 2595–2608, https://doi.org/10.1080/01431160110115023."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "2  week 3",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Week 5",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Week 1-Introduction to Remote Sensing",
    "section": "1.1 summary",
    "text": "1.1 summary\n\n1.1.1 What is remote sensing?\nRemote sensing is like a high-tech camera that takes pictures of the Earth. These “cameras” are installed on various platforms, such as high-altitude aircraft or drones and satellites. They capture details of the Earth’s surface from long distances and help us understand and monitor changes in the environment.\n\n\n1.1.2 Active and passive sensors\nAs mentioned above, these “cameras” are sensors. The difference between active and passive sensors mainly lies in the source of energy: passive sensors rely on energy reflected from the sun or artificial light sources, while active sensors can actively emit electormagentic waves (such as radar waves or X-rays) and receive the signals reflected back. This significantly improves the performance and accuracy of active sensors at night or in adverse weather conditions.\n\n\n1.1.3 Electromagnetic radiation\n\nRemote sensing sensors primarily focus on receiving electromagnetic radiation, which includes all waves reflected from the surface of an object.\nElectromagnetic wave has two components: electric fields (E) and magnetic fields (F). The electric and magnetic fields are perpendicular to each other, and they are also perpendicular to the direction of propagation of the wave.\nThe main elements of electromagnetic waves include: wavelength (The distance between two adjacent wave crests) frequency (the number of vibrations per unit time, which determines the color or energy level of the wave) amplitude (the height of the wave, which affects the intensity or brightness of the wave) speed ( The propagation speed of electromagnetic waves in vacuum is usually the speed of light, which is approximately 3.00×10^8 meters/second).\nThe electromagnetic spectrum is the range of electromagnetic radiation formed by wavelength or frequency, including short-wave gamma rays, X-rays, and ultraviolet light, through the spectrum visible to the human eye (red, orange, yellow, green, blue, indigo, violet), to long-wave infrared rays, microwaves, and radio waves .\nElectromagnetic waves interact with the Earth’s surface by being absorbed, transmitted, or reflected. The specific interaction depends on the surface material and the wave’s properties. In the atmosphere, electromagnetic energy encounters particles that can scatter the waves. The scattering varies by the size of the particles relative to the wavelength: Rayleigh scattering occurs with smaller particles, Mie scattering with similar-sized particles, and non-selective scattering with larger particles. This scattering affects the colors we see in the sky, especially at sunrise and sunset when the path through the atmosphere is longer, leading to more scattering of shorter wavelengths and allowing longer wavelengths like red and orange to dominate the sky.\n\n\n\n1.1.4 Four resolutions\nSpectral resolution: refers to the sensor’s ability to distinguish different wavelengths (or frequencies) of electromagnetic radiation. Different features on Earth’s surface have unique spectral signatures which can be detected by the sensor. Hyperspectral remote sensing can distinguish hundreds of narrow wavelength bands for detailed analysis of material composition.\nSpatial resolution: refers to the size of the ground area represented by one pixel in the image, which determines the level of detail of the remote sensing image. High spatial resolution means more detailed ground information.\nTemporal resolution: refers to how often the sensor re-covers the same area and is critical for monitoring changes (such as vegetation growth, urban expansion).\nRadiation resolution: refers to the sensor’s ability to detect and distinguish between different radiation intensity levels. High radiometric resolution helps identify weak radiometric changes.\n\n\n1.1.5 The choice of data\nWhen selecting remote sensing data, it’s crucial to consider both environmental and sensor constraints which dictate the suitability of data types for specific needs. For instance, active remote sensing techniques like radar are preferable during cloudy conditions as they can penetrate cloud cover. High spectral resolution data might be required for detailed vegetation analysis. Thus, the choice of remote sensing data hinges on the balance of these factors alongside the mission’s objectives, environmental conditions, and sensor capabilities."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2-Sentinel 1",
    "section": "",
    "text": "Here is a short presentation discussing the Sentinel 1 mission:"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Week 3-Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\n\nGeometric Corrections: Addressing distortions due to view angle, topography, wind, and Earth’s rotation. Algorithms such as linear regression, Helmert transformation, polynomial transformations (1st to 3rd degree), Thin Plate Spline (TPS), and projective transformation are chosen based on their ability to minimize RMSE.\nAtmospheric Corrections: Overcoming atmospheric scattering and attenuation effects via methods like Empirical methods, Dark Object Subtraction(DOS), Pseudo-invariant Features (PIFs) or through complex atmospheric radiative transfer models.\nTopographic/Orthorectification Corrections: Adjusting the viewing angle to treat slope and elevation distortions, often requiring solar zenith and azimuth angles through techniques like Cosine correction, Minnaert correction, Statistical Empirical correction, and C Correction (an advancement of the Cosine correction).\nRadiometric Calibration: Converting Digital Numbers to spectral radiance, adjusting for the sensor’s measurements of upwelling radiation.\n\n\n\n3.1.2 Data Joining\n\nMosaicking: The process of combining multiple images, ensuring they blend seamlessly at the edges, often involves histogram matching and feathering.\n\n\n\n3.1.3 Enhancements\n\nEnhancements refine the visual and analytical quality of satellite imagery without altering the actual data values.\nMethods including Contrast Enhancement, Ratio, Filtering, PCA, and Texture Analysis.\nTechniques such as contrast enhancement make images more interpretable, while PCA reduces dimensionality, isolating significant changes in multi-temporal analysis."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week 5-Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Introduction to GEE\n\nGEE is a cloud computing platform for planetary-scale geospatial analysis.\nIt’s structured into a client-side (user interface) and a server-side (data storage and processing).\nThe server-side uses Earth Engine objects prefixed with ‘ee’.\n\n\n\n5.1.2 Terminology in GEE\n\nRaster data is referred to as “Image.”\nVector data is termed “Feature.”\nCollections of images and features are called “ImageCollection” and “FeatureCollection” respectively.\n\n\n\n5.1.3 Interface and Language\n\nGEE uses Javascript for scripting, which is similar to Python and R.\nVariables and objects in Javascript are defined with ‘var’, where objects can contain multiple values.\n\n\n\n5.1.4 Key Concepts\n\nScale refers to pixel resolution, influenced by the volume of analysis and set by the output requirements.\nProjections in GEE are simplified as they’re automatically converted to Mercator projection, requiring no user intervention.\n\n\n\n5.1.5 Core Processes\n\nGEE enables various geometry operations such as spatial joins and filtering.\nIt incorporates methods for machine learning, including both supervised and unsupervised classification, and deep learning.\nIt supports applications such as generating online charts.\n\n\n\n5.1.6 Specialized Functions\n\nImage reduction techniques like reducing by region or neighborhood.\nStatistical analysis through linear regression.\nSpatial analysis using joins, specifically spatial joins and intersects."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week 6-Classification 1",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week’s curriculum provided an in-depth look at the use of machine learning for classification in remote sensing.\n\n6.1.1 Classification and Regression Trees (CART)\n\nEmploys a tree structure where nodes denote features, branches represent decision rules based on feature values, and leaf nodes indicate predicted class labels (for classification) or numerical values (for regression).\nUses Gini impurity (for classification) or the lowest sum of squared residuals (SSR) (for regression) to recursively partition the feature space, aiming to enhance homogeneity within subsets.\nIncludes mechanisms to prevent overfitting, such as setting a maximum depth for each node and a minimum number of samples per node, thus improving generalization.\n\n\n\n6.1.2 Random Forest\n\nA collective of decision trees, each serving as a weak learner, integrated using ensemble learning techniques to bolster overall predictive performance.\nIncorporates randomness through bootstrapping (resampling with replacement) and feature randomness, ensuring a diverse set of trees and reducing feature correlation.\nFor prediction, it aggregates the outcomes of all trees, selecting the most frequent class (classification) or averaging the results (regression) to produce a final decision.\n\n\n\n6.1.3 Support Vector Machines (SVM)\n\nActs as a linear binary classifier, akin to logistic regression but with a focus on maximizing the margin between two classes.\nThe classifier identifies support vectors and constructs a separating hyperplane, termed the maximum margin classifier.\nAdjustments to parameters like C and gamma allow the model to balance the margin’s width against the error rate, affecting the classifier’s sensitivity to training data distribution.\n\nWithin the realm of remote sensing, supervised and unsupervised learning play pivotal roles in image classification\n\nSupervised Learning is used when we have labeled data to train the model. Algorithms such as Random Forest and SVM are used to learn from the training data and then classify new, unlabeled data with precision.\nUnsupervised Learning comes into play when there is no labeled data available. Methods like k-means and ISODATA cluster the data based on inherent patterns without prior knowledge, which is particularly useful for initial explorations of land cover types in satellite images.\n\nBoth learning paradigms are instrumental in advancing the classification and analysis of remote sensing data, with supervised learning providing precision where labels are known, and unsupervised learning offering exploratory insights when such labels are not available."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  Week 7-Classification 2",
    "section": "",
    "text": "In the realm of remote sensing, accurately classifying Earth observation (EO) images is paramount. Traditional pixel-based classification methods, while useful, often overlook the spatial relationship between pixels, known as adjacency. This oversight can be problematic due to the geographic principle that spatial entities tend to be more similar to their immediate neighbors than to those further away. It’s also rare for a pixel to be completely homogenous, meaning it typically comprises a mixture of different land covers. To address these challenges, this week we delve into Object-Based Image Analysis (OBIA) and sub-pixel analysis, which offer a more refined approach to classification tasks.\n\n7.0.1 Object-Based Image Analysis (OBIA)\nOBIA represents a shift from pixel to object-level analysis. Rather than analyzing each pixel individually, OBIA groups pixels into superpixels or supercells based on their spectral homogeneity. This process is adeptly handled by the Simple Linear Iterative Clustering (SLIC) algorithm, which creates these superpixels by:\n\nInitializing centroids within the image based on a predefined number of superpixels.\nIteratively clustering pixels based on their spectral similarity and proximity to centroids.\nAdjusting centroids and boundaries to minimize intra-object variance and maximize inter-object distinction.\n\nThe process relies on two key hyperparameters: the distance between initial centroids (s) and the compactness factor (m), which balances color similarity and proximity. The output is a segmented image that better reflects the true spatial structure of the observed area.\n\n\n7.0.2 Sub-Pixel Analysis\nWhere OBIA groups pixels, sub-pixel analysis goes a level deeper by examining the composition within individual pixels. Recognizing that pixels often contain a mix of land cover types, sub-pixel analysis estimates the proportion of each cover type present. Spectral Mixture Analysis (SMA) is commonly employed for this purpose, using spectrally pure endmembers as references to deconstruct a pixel’s spectral signature into its constituent parts.\nThe methodology can be outlined as follows:\n\nIdentify spectrally pure endmembers that represent distinct land cover types.\nApply a matrix-based approach to solve for the proportions of each land cover type within the pixel, often visualized through a V-I-S (Vegetation-Impervious surface-Soil) model.\n\n\n\n7.0.3 Accuracy Assessment\nAn integral part of these techniques is accuracy assessment. New datasets are used to validate classification outputs, with strategies such as spatial cross-validation enhancing the reliability of the results. Spatial cross-validation partitions the data into spatially disjoint sets, avoiding the pitfall of training and testing the model on autocorrelated samples. This method ensures that the model’s performance is tested on geographically independent data points.\n\n\n7.0.4 Conclusion\nOBIA and sub-pixel analysis present a substantial improvement over traditional methods, acknowledging the complex nature of spatial data. These techniques not only consider the homogeneity within pixels but also the relatedness of adjacent areas, thus creating more accurate and geographically sensible classification models."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week 8-Temperature",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThe focus for this week is the phenomenon known as Urban Heat Island (UHI), where urban areas experience higher temperatures than their rural surroundings. This effect is primarily attributed to factors such as limited greenery, heat-absorbing construction materials, and dense urban layouts that restrict airflow and enhance heat retention. Notably, UHIs can lead to severe social, economic, and environmental consequences, evidenced by the 2010 heat disaster in Ahmedabad that killed more than 1,000 people.\nGlobally, there are policies addressing UHIs, notably within the Sustainable Development Goals, advocating for more verdant urban areas to temper the UHI effect. Additionally, the United Nations Environment Program’s “Beat the Heat handbook” furnishes planners with a systematic approach and a suite of interventions adaptable to various urban contexts.\nRemote sensing is a critical tool that offers comprehensive temperature data, which is essential for a deeper understanding of UHI dynamics. Through satellites like Landsat and MODIS, it provides detailed temperature observations. The high temporal resolution of MODIS, in particular, enables frequent monitoring, which enhances our ability to track and analyze temperature variations over time.\nIn the context of UHI, remote sensing data is invaluable for policy and decision-making. It enables the detection and ongoing surveillance of UHI effects, thereby facilitating targeted and effective urban planning interventions. Moreover, this data can illuminate the complex interactions within urban environments that contribute to UHI, guiding the development of strategies to counteract them.\nIn summary, remote sensing stands as an indispensable ally in the quest to understand and mitigate the UHI effect. It provides the detailed, nuanced temperature data necessary for cities to enact policies that will effectively cool urban environments and reverse the trend of rising urban temperatures.\n\n8.1.1 Application\n\nRadiometer instrument data from the Copernicus Sentinel-3 mission on 2023/07/17 shows extreme surface temperature conditions in some European cities. Surface temperatures reached 45°C in Bucharest and Rome, and 50°C in Catania and Nicosia. Such heat events are likely to become more frequent and severe as climate change intensifies. By measuring the energy radiated from the Earth through satellite instruments, scientists can better understand and predict weather and climate patterns and monitor natural disasters such as fires, which is particularly important for agriculture and urban planning.\nThe picture below shows the surface temperature map of Europe on July 17, 2023.\n\n\n\n\n\n\n\nStreutker, D. R.(2002) investigated the Urban Heat Island (UHI) effect in Houston, Texas, using remote sensing data from satellite sensors to analyze surface temperatures over two years. It differentiated urban from rural temperatures by modeling the UHI as a Gaussian surface over a flat rural baseline, without relying on ground measurements. The analysis revealed that the UHI’s intensity inversely correlated with the surrounding rural area’s temperatures but its size remained constant regardless of temperature variations. Essentially, this approach provided a comprehensive view of the UHI effect’s magnitude and spatial extent solely from satellite observations, showcasing remote sensing’s potential in urban climate studies."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week 7-Classification 2",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nIn the realm of remote sensing, accurately classifying Earth observation (EO) images is paramount. Traditional pixel-based classification methods, while useful, often overlook the spatial relationship between pixels, known as adjacency. This oversight can be problematic due to the geographic principle that spatial entities tend to be more similar to their immediate neighbors than to those further away. It’s also rare for a pixel to be completely homogenous, meaning it typically comprises a mixture of different land covers. To address these challenges, this week we delve into Object-Based Image Analysis (OBIA) and sub-pixel analysis, which offer a more refined approach to classification tasks.\n\n7.1.1 Object-Based Image Analysis (OBIA)\nOBIA represents a shift from pixel to object-level analysis. Rather than analyzing each pixel individually, OBIA groups pixels into superpixels or supercells based on their spectral homogeneity. This process is adeptly handled by the Simple Linear Iterative Clustering (SLIC) algorithm, which creates these superpixels by:\n\nInitializing centroids within the image based on a predefined number of superpixels.\nIteratively clustering pixels based on their spectral similarity and proximity to centroids.\nAdjusting centroids and boundaries to minimize intra-object variance and maximize inter-object distinction.\n\nThe process relies on two key hyperparameters: the distance between initial centroids (s) and the compactness factor (m), which balances color similarity and proximity. The output is a segmented image that better reflects the true spatial structure of the observed area.\n\n\n7.1.2 Sub-Pixel Analysis\nWhere OBIA groups pixels, sub-pixel analysis goes a level deeper by examining the composition within individual pixels. Recognizing that pixels often contain a mix of land cover types, sub-pixel analysis estimates the proportion of each cover type present. Spectral Mixture Analysis (SMA) is commonly employed for this purpose, using spectrally pure endmembers as references to deconstruct a pixel’s spectral signature into its constituent parts.\nThe methodology can be outlined as follows:\n\nIdentify spectrally pure endmembers that represent distinct land cover types.\nApply a matrix-based approach to solve for the proportions of each land cover type within the pixel, often visualized through a V-I-S (Vegetation-Impervious surface-Soil) model.\n\n\n\n7.1.3 Accuracy Assessment\nAn integral part of these techniques is accuracy assessment. New datasets are used to validate classification outputs, with strategies such as spatial cross-validation enhancing the reliability of the results. Spatial cross-validation partitions the data into spatially disjoint sets, avoiding the pitfall of training and testing the model on autocorrelated samples. This method ensures that the model’s performance is tested on geographically independent data points.\n\n\n7.1.4 Conclusion\nOBIA and sub-pixel analysis present a substantial improvement over traditional methods, acknowledging the complex nature of spatial data. These techniques not only consider the homogeneity within pixels but also the relatedness of adjacent areas, thus creating more accurate and geographically sensible classification models."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Week 4-Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nAhmedabad’s Heat Action Plan (HAP) is a comprehensive early warning system and preparedness plan for dealing with extreme heat events. This plan aims to improve preparedness, information sharing and response coordination through immediate and long-term actions to reduce the health impacts of extreme heat on vulnerable populations.\nIn May 2010, Ahmedabad experienced a major heat wave, resulting in an additional 1,344 deaths. This heat wave serves as a wake-up call for action, preparedness and community outreach across government agencies with the goal of saving lives. The Ahmedabad Municipal Corporation (AMC) prepared its first heat action plan in 2013 in collaboration with domestic and international academic experts and drawing on global best practices.\nThe Heat Action Plan aims to implement four key strategies:\n\nBuild public awareness and community outreach: Communicate the risks of heat waves through media and information materials and implement measures to prevent heat-related illness and death. This includes the use of modern media such as SMS, email, radio and mobile applications to disseminate information, especially to vulnerable populations.\nActivate early warning systems and interagency coordination: Create formal communication channels to alert government agencies, weather centers, health officials, hospitals, emergency responders, community groups, and the media about predicted extreme heat.\nEnhancing the Capacity of Healthcare Professionals: Focus on the training of primary medical staff and other medical and community health workers to enable them to effectively prevent and manage heat-related cases to reduce mortality and morbidity.\nReducing heat exposure and promoting adaptation measures: Increase advocacy and communication on preventive measures, drinking water and heat escape spaces by developing maps of high-risk areas in the city, working with NGOs, and expanding outreach to the city’s most vulnerable communities communication.\n\nThis plan is not only India’s first comprehensive response plan to face extreme heat, but also provides a guide for other cities and regions to take precautionary measures such as heat action plans when the weather becomes increasingly hot and extreme. At the same time, countless lives are saved."
  },
  {
    "objectID": "week4.html#apliacation",
    "href": "week4.html#apliacation",
    "title": "4  Week 4-Policy",
    "section": "4.2 Apliacation",
    "text": "4.2 Apliacation"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Week 1-Introduction to Remote Sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nRemote sensing data’s ability to capture detailed information over broad, often inaccessible areas, and at regular intervals, makes it a powerful tool for environmental monitoring and disaster management.\n\n1.2.1 Sentinel-3\nThe utilization of Copernicus Sentinel-3 data for monitoring high temperatures in Ahmedabad demonstrates the critical role satellite observations play in urban heat management and climate monitoring. Sentinel-3, with its advanced instruments like the Sea and Land Surface Temperature Radiometer (SLSTR), provides accurate measurements of land surface temperature (LST), which is essential for understanding and addressing the impacts of heatwaves.\n\n\n\n\n\nIn Ahmedabad, it reached 47°C, peaking at 65°C in areas around Ahmedabad, marked in deep red.\n\n\n1.2.2 In india\nNavalgund, Ranganath R., et al(2007) highlights the vital role of India’s remote sensing applications across various fields. It showcases advancements in agriculture through crop monitoring and yield estimation, water security through groundwater prospect mapping and reservoir monitoring, and environmental protection by tracking forest cover and biodiversity. Furthermore, it addresses disaster management through real-time flood and drought assessments, demonstrating the significant impact of the Indian Space Programme on sustainable development and disaster resilience.\n\n\n\n\n\nThe graph represents the spectral reflectance characteristics of different targets, including (1) clouds, (2) snow, (3) vegetation, (4) soil, and (5) water, and the IRS-P3 MOS-A, B, and C sensor channels location (provided by DLR, Germany)."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1-Introduction to Remote Sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nThis was my first lesson in remote sensing technology. From these, I learned how remote sensing technology allows us to observe and analyze the Earth from different angles and distances. The acquisition and analysis of remote sensing data opens up new perspectives in studying phenomena on the Earth’s surface and atmosphere, allowing us to monitor important areas such as agricultural production, water resources management, and environmental changes. In particular, I realized the importance of accurate information and scientific explanations on how to correctly understand the scientific principles of natural phenomena, such as why the sky is blue. Through the correct explanation of Rayleigh scattering, I learned that the shorter wavelength light (blue light) in the atmosphere scatters more strongly than the longer wavelength light (such as red light), thus causing the blue sky we see. Additionally, this learning experience reinforced my understanding of the natural world by highlighting the importance of continuous learning and verifying the accuracy of the information we receive."
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Week 3-Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Ratio: Normalised Difference Vegetation Index (NDVI)\nPei, Fengsong, et al(2021) explored the use of NDVI in monitoring extreme precipitation events in the Middle and Lower Reaches of the Yangtze River (MLR-YR) in China from 1982 to 2012. It evaluates how minimum, mean, and maximum NDVI values, derived from satellite data, can reflect the variability in vegetation activity due to extreme precipitation changes. The research finds that maximum NDVI is particularly responsive to these changes, and both maximum and minimum NDVI demonstrate significant spatial variability in response to extreme precipitation\n\n\n\n\n\nThis set of maps displays the standard deviation of the Normalized Difference Vegetation Index (NDVI) in the Middle and Lower Reaches of the Yangtze River in China. Map (a) represents the standard deviation of the minimum NDVI values, indicating the variability of the lowest NDVI readings, which might reflect the least vegetative state or periods of low vegetation health. Map (b) shows the standard deviation of the mean NDVI, which represents the average variability in vegetation greenness over time. Map (c) depicts the standard deviation of the maximum NDVI values, highlighting the variability in the peak vegetation period or the healthiest vegetative state. The different shades of green to yellow across the maps indicate areas with varying levels of NDVI variability. Areas with higher standard deviation values, shown in darker colors, may experience more significant changes in vegetation due to various factors such as seasonal changes, agricultural practices, or extreme weather events. These maps are useful for identifying patterns of vegetation dynamics and potential areas of ecological stress or change.\n\n\n3.2.2 Texture\nJames R. Irons and Gary W. Petersen explores the application of image texture in the digital analysis of remotely sensed data.They develops software to quantify image texture and applies it to both image enhancement and thematic classification of remotely sensed Landsat-2 MSS data.They use SUBTEXT to calculate various local properties within pixel windows to generate texture transforms, which provide discrete measurements for each pixel.These texture transforms effectively delineate edges and enhance imagery."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week 3-Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nThis week’s content was exponentially more difficult for me. There were too many unfamiliar terms, and the mathematical logic behind each method was difficult for me to understand. In comparison, the correction part is easier to understand, it’s like data cleaning. However, unlike panel data, remote sensing data contain a large amount of spatiotemporal information, so unique methods must be used to correct them. But many remote sensing products come pre-corrected, which greatly simplifies the analyst’s workflow.\nThe enhancement part was harder for me to understand, so I read the literature to see how academics were using enhancement techniques. Finally I came to the conclusion that enhancement is a method to pursue specific remote sensing information. Similar to when we deal with panel data, we need to find the variance or average for different needs, and the same is true for enhancement. It is based on data reprocessing for research purposes.\nCorrecting, joining data sets, and enhancements together constitute remote sensing data preprocessing. Advances in preprocessing not only enhance visual interpretation of remote sensing but also significantly improve spectral accuracy for a variety of applications."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Week 4-Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn order to promote better implementation of HAP, I hope to collect land surface temperature (LST) data and normalized difference vegetation index (NDVI), urban heat island detection data and water body mapping data to draw a high temperature vulnerability map. In the process :\n\nLand surface temperature (LST) data can be obtained from satellites such as the Moderate Resolution Imaging Spectroradiometer (MODIS) on the Terra and Aqua satellites or the Land Surface Temperature Monitoring (LSTM) mission of Copernicus Sentinel-3.\nThe Normalized Difference Vegetation Index (NDVI) is derived from MODIS or Copernicus Sentinel-2 satellite data and measures the density and health of vegetation. NDVI is critical for assessing areas with lower vegetation cover, which may be more susceptible to heat waves due to a lack of cooling provided by plant transpiration.\nUrban heat island (UHI) detection, primarily with the help of high-resolution satellite images (such as those from the Landsat series or Copernicus Sentinel-2) can be used to map urban areas and detect UHI impacts. By comparing daytime and nighttime temperature changes, areas with significant urban heat island impacts can be identified, highlighting areas where urban populations are at greater risk during heat waves.\nWater body mapping. Water is a potential natural cooling resource. The availability and seasonal changes of water bodies in and around urban areas can be mapped through satellite data such as Landsat or Sentinel-2.\nSubsequently, I hope to integrate the above various satellite data sets for a comprehensive spatial analysis. GIS (geographic information system) tools and spatial analysis methods can be used to overlay, compare and correlate different data layers to identify areas with high surface temperatures, low vegetation cover, and significant and limited urban heat island effects. Enter a body of water.\nFinally the heat vulnerability index (HVI) was developed. HVIs are constructed for each region in Ahmedabad using integrated satellite data within a GIS framework. The index will incorporate environmental and spatial factors that contribute to thermal vulnerability, providing a risk assessment by region."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week 4-Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nEvery major policy is introduced to solve imminent practical problems, and for high temperature hazards, the use of remote sensing technology can perfectly complement the technical deficiencies and promote policy implementation. In fact, Ahmedabad has implemented many measures to avoid heat hazards, such as using extreme heat warning systems. The early warning system is designed to generate probabilistic predictions of maximum temperatures and the probability of temperatures reaching specific critical thresholds based on group consensus based on analysis of mortality and temperature data. Forecasts are generated 7 days in advance and sent to AMC nodal officers via email as shown below.\n\n\n\n\n\nThis early warning system worked well in the first year of policy implementation, but then some problems were discovered, such as the possibility of inaccurate predictions, which requires more accurate technology to improve. I think the method I proposed has a certain degree of rationality and It is feasible, and its successful experience is very suitable for promotion throughout India, which is suffering from high temperature hazards."
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Week 5-Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nFirst, I used the new tool GEE I learned this week to draw the surface reflectance of the Delhi area. Surface reflectance measures the proportion of light that is reflected from the earth’s surface, corrected to account for atmospheric conditions. This data is critical for various types of analyses, such as assessing vegetation health, urban heat distribution, or water body extents.\n\n\n\n\n\nThen I did texture measurement and PCA analysis, and finally got the picture below\n\n\n\n\n\nTamiminia, Haifa, et al (2020) provides a comprehensive overview of the use of Google Earth Engine (GEE) in processing and analyzing large-scale geospatial data for environmental monitoring. The study examines peer-reviewed articles that utilized GEE and categorizes them based on features such as data type, sensor type, study area, spatial resolution, application strategy, and analytical methods.\n\nThis is a summary of ready-to-use products applied in GEE.\n\n\n\n\n\n\nThe most significant application, at 27%, is the assessment of Vegetation Indices, which are critical for monitoring plant health, vegetation cover, and biomass production. Land cover analysis, which helps in understanding the distribution of different types of land and surface materials, constitutes 17% of the applications, tied with Hansen Global Forest Change, which tracks deforestation and forest dynamics. Digital Elevation Models (DEM), which provide information on terrain elevations, account for 11% of usage."
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Week 7-Classification 2",
    "section": "7.2 Application",
    "text": "7.2 Application\n\n7.2.1 part 1\nIn the past few weeks, I have been paying close attention to Ahmedabad in India because of its high temperature hazards. In the application of this chapter, I discovered another way to mitigate the dangers of heat. Kai Liu and colleagues conducted a study on urban surface energy fluxes in Suzhou, China, using Sub-Pixel Analysis via Multiple Endmember Spectral Mixture Analysis (MESMA) to assess the detailed composition of urban land cover. This method allowed for the detailed assessment of vegetation fractional coverage (VFC) and the percentage of impervious surface area (ISA%) within each pixel of satellite imagery, beyond the traditional one land cover type per pixel assumption.\nThis are maps of land coverage, LCTs classification and LCT at 1040 LT, derived from 30-m LANDSAT-5 TM acquired on 24, May 2010. (a) Vegetation fraction coverage; (b) impervious surface coverage; (c) LCT classification; (d) land surface temperature.\n\n\n\n\n\nThe research results revealed two key findings:\n\nCooling Effect of Vegetation: Areas with higher vegetation fractional coverage (VFC) showed a cooling effect, indicated by higher latent heat flux (LE) and lower land surface temperatures (LST). This underscores the importance of vegetation in urban areas for mitigating heat through evapotranspiration.\nHeat Retention in Urbanized Areas: Urbanized zones with a higher percentage of impervious surface area (ISA%) exhibited increased sensible heat flux (H) and higher LST, indicating that these areas absorb and retain more heat compared to their less urbanized counterparts.\n\nThese findings highlight the significant impact of urban land cover composition on the thermal environment, emphasizing the need for integrating green spaces in urban planning to combat the urban heat island effect and promote sustainable urban living.\n\n\n7.2.2 part 2\nHowever, except Ahmedabad, there is another city in India, Delhi, which is also facing problems such as land degradation and desertification due to its geographical location and urbanization pressure.\nAtiqur Rahman and his team leveraged remote sensing data and Geographic Information System (GIS) techniques to track land use and land cover changes in the North-West District of Delhi from 1972 to 2003. They combined high-resolution ASTER images with historical Survey of India Toposheets, using digitization, geo-referencing, and image classification methods, including supervised classification with the Maximum Likelihood Classifier. Through change detection analysis, they documented significant shifts from agricultural land to urban areas.The study validated the classification results against ground truth data to ensure accuracy, and integrated the findings into GIS for enhanced analysis and visualization. The research results are as follows.\n\n\n\n\n\nThis picture shows:\n\nA significant reduction in agricultural land, from 92.06% in 1972 to 64.71% in 2003.\nAn increase in built-up areas from 6.31% to 34% over the same period, indicating urban expansion.\nUrban growth has primarily occurred at the expense of agricultural lands.\nPopulation growth due to migration from smaller cities and rural areas of Delhi is a primary driver of these land use changes."
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Week 5-Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nGoogle Earth Engine (GEE) is indeed a powerful tool that has revolutionized the field of remote sensing and geospatial analysis. Its ability to handle large datasets efficiently and perform complex geospatial processing tasks quickly is impressive. By providing access to a vast catalog of satellite imagery and geospatial datasets, along with robust computational power, GEE significantly reduces the time and effort required for data analysis.\nThe convenience of GEE is evident in the way it simplifies workflows that traditionally involved multiple steps and software tools like QGIS and SNAP (Sentinel Application Platform). For example, tasks such as filtering a collection of satellite images, reducing data based on specific parameters, and visualizing the results can be scripted and executed in GEE’s Code Editor, often in a matter of minutes, depending on the complexity and size of the task. Furthermore, GEE’s speed and efficiency don’t come at the expense of precision or the range of possible analyses.\nAlthough GEE is very convenient to use, it does not mean that using GEE does not require coding skills. GEE uses a different programming language, JavaScript. Although I was a little uncomfortable at first, after a while I found that I could still use GEE very smoothly. I believe this must be the coding foundation I learned in R that helped me."
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Week 6-Classification 1",
    "section": "6.2 Application",
    "text": "6.2 Application\n\nM. Pal(2005) focuses on utilizing the Random Forest (RF) classifier for land cover classification from remote sensing data. It aims to present the results obtained with the RF classifier and to compare its performance with Support Vector Machines (SVMs) in terms of classification accuracy, training time, and user-defined parameters.The study utilized Landsat Enhanced Thematic Mapper Plus (ETM+) data for an area in the UK and involved classifying seven different land cover types. It concluded that the RF classifier performs equally well as SVMs in terms of classification accuracy and training time for the given dataset. The RF classifier also proved to be less sensitive to overfitting, a crucial advantage when working with complex datasets.\nThe table below shows final classification accuracy, kappa coefficient and training time of both classifiers.\n\n\n\n\n\n\n\nIn a study of my native Xinjiang, China, Tian, Shaohong, et al (2020) developed a Random Forest (RF) model by fusing high-resolution Pleiade-1B data with multi-date Landsat-8 NDVI series to classify wetland landcovers. The modeling process involved feature extraction and optimization, including geometric, spectral, and phenological characteristics, to address the classification challenges in arid wetlands.\nThis is the classification results of the RFC (a); SVM (b); and ANN (c) models.\n\n\n\n\n\n\n\nThe RF model outperformed other machine learning classifiers, achieving an overall accuracy of 93% and a Kappa coefficient of 0.92, demonstrating its effectiveness in wetland classification. The inclusion of phenological information through NDVI series significantly improved the discrimination between vegetation types with similar spectral features but different growth patterns. This study showcases the potential of multi-sensor data fusion and RF classification in enhancing wetland monitoring and management in arid regions."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Week 6-Classification 1",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThe content learned in this class feels very familiar to me, because in the casa0006 class we have also been exposed to the application of machine learning in classification, so I am very curious about how to apply these technologies to remote sensing data. After comparing, I found when applying machine learning for classification tasks, whether in remote sensing data or panel data, the core goal is to categorize entities or pixels into predefined classes based on their features. However, they still have differences:\n\nData Complexity: Remote sensing data is spatial-temporal, capturing physical phenomena in images, while panel data tracks variables over time and entities, focusing on temporal dynamics without inherent spatial components.\nApplications: Remote sensing primarily serves environmental monitoring and land use classification. In contrast, panel data finds use in economics, social sciences, and epidemiology, emphasizing temporal changes and impacts on entities.\nSpatial vs. Temporal Analysis: Spatial autocorrelation is central to remote sensing, requiring spatial analysis techniques. Panel data analysis often addresses time-based autocorrelation and heteroskedasticity, employing models to handle individual-specific effects.\n\nBoth applications share the machine learning classification pipeline, including data preprocessing, feature extraction, model selection, and validation, but they adapt these steps to meet their specific data challenges and analytical objectives."
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Week 7-Classification 2",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis week I learned two more in-depth and more refined classification methods. These contents include parts that I am familiar with. For example, I have been exposed to the concept of spatial autocorrelation in the CASA0005 course, but the overall concept is still a bit obscure to me. Difficult to understand. So I looked for relevant papers to read, and was pleasantly surprised to find that this new classification method plays a very important role in classifying land coverage, and I got a new method of mitigating thermal hazards from the paper, which is consistent with my policy in the fourth week. Some of the contents echoed, giving me a sense of integrated knowledge. It can also be seen that overheating of the earth’s surface is a global problem affecting society, economy and environment. As a result, every government is trying to cool down their own land. This requires accurate identification of land types. Object-Based Image Analysis (OBIA) and Sub-Pixel Analysis are both good methods for identifying land types."
  },
  {
    "objectID": "week8.html#reflections",
    "href": "week8.html#reflections",
    "title": "8  Week 8-Temperature",
    "section": "8.2 Reflections",
    "text": "8.2 Reflections\nThis week, I’ve chosen to discuss the urban heat island effect for two main reasons. Firstly, I have already touched upon Synthetic Aperture Radar (SAR) in the second week, and I want to explore a different topic. More importantly, the urban heat island effect represents a serious and urgent global challenge that demands immediate action for mitigation. It’s a complex issue, exacerbated by the irreversible trend of rapid global urbanization, with each city inhabitant inadvertently contributing to the problem.\nThe question then arises: How can we control the urban heat island effect? Addressing this issue requires interventions at a macro level, beyond the immediate reach of individual efforts. This is where the value of remote sensing data becomes particularly clear. By utilizing remote sensing data, we can create vulnerability maps to identify areas at high risk of heat-related disasters. Moreover, the proactive analysis of remote sensing data is crucial for disaster prevention.\nCertainly! Addressing the urban heat island effect goes beyond merely identifying and analyzing high-risk areas; it involves a comprehensive approach that includes policy-making, urban planning, and community engagement. Reflecting on this issue, it becomes clear that an interdisciplinary strategy is essential. Urban planners and policymakers need to work closely with environmental scientists, architects, and the public to implement solutions such as increasing green spaces, enhancing urban albedo with reflective materials, and promoting sustainable urban design.\nMoreover, the role of education and awareness cannot be overstated. Informing residents about the urban heat island effect and ways to mitigate it through simple actions like planting trees or choosing lighter-colored building materials can have a significant impact. Additionally, leveraging technology for smarter urban development can lead to more resilient and cooler cities.\nThe challenge also highlights the importance of data accessibility and the need for ongoing research. As remote sensing technologies evolve, they offer unprecedented opportunities to monitor urban heat islands in real time, predict hotspots, and evaluate the effectiveness of mitigation strategies.\nIn conclusion, combating the urban heat island effect requires a collaborative effort that integrates technology, policy, and community action. It’s a reminder of our collective responsibility to foster sustainable urban environments, not just for the present, but for future generations. The path forward is complex, but with continued innovation and cooperation, we can make significant strides in alleviating the impacts of urban heat islands."
  }
]